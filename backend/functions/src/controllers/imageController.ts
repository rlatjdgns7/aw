/**
 * @fileoverview Unified image processing controller that combines OCR and additive search.
 * Provides a single endpoint to process images and return complete results.
 * Uses Google Cloud Vision API for high-accuracy OCR processing.
 */

import dotenv from 'dotenv';
dotenv.config();

import { Response } from 'express';
import { AuthenticatedRequest } from '../middleware/authMiddleware';
import { v4 as uuidv4 } from 'uuid';
import { ImageAnnotatorClient } from '@google-cloud/vision';
import { searchAdditivesWithFuzzyMatching } from '../utils/additiveSearchUtils';

// Google Cloud Vision client - with explicit configuration for better error handling
const visionClient = new ImageAnnotatorClient({
  keyFilename: process.env.GOOGLE_APPLICATION_CREDENTIALS || './service-account-key.json'
});


/**
 * Unified image processing controller.
 * Processes an image with OCR and immediately returns search results for found additives.
 */
export const imageController = {
  /**
   * Process an image with OCR and search for additives in one operation.
   * This replaces the separate /ocr/process and /search/image endpoints.
   * 
   * @param {AuthenticatedRequest} req - Express request object with authentication and image file
   * @param {Response} res - Express response object
   * @returns {Promise<void>} Promise that resolves when the operation completes
   * 
   * @example
   * POST /api/image/process (with multipart/form-data image file)
   * Response: {
   *   success: true,
   *   data: {
   *     jobId: "uuid-string",
   *     extractedText: "text from image",
   *     additives: [{ id: "123", name: "Additive Name", ... }, ...]
   *   }
   * }
   */
  async processImage(req: AuthenticatedRequest, res: Response): Promise<void> {
    try {
      if (!req.file) {
        res.status(400).json({ 
          success: false,
          error: 'Image file is required' 
        });
        return;
      }

      const jobId = uuidv4();

      // Skip Firestore for now - process directly

      try {
        // Step 1: Process image with Google Cloud Vision OCR
        console.log(`Starting Google Cloud Vision OCR processing for job ${jobId}`);
        
        const extractedText = await processImageWithVisionAPI(req.file.buffer);
        console.log(`OCR completed for job ${jobId}:`, extractedText);

        // Step 2: Search for additives in the extracted text using shared utility
        const additives = await searchAdditivesWithFuzzyMatching(extractedText);
        console.log(`Found ${additives.length} additives for job ${jobId}`);

        // Step 3: Results processed successfully

        // Step 4: Return complete results immediately
        res.json({
          success: true,
          data: {
            jobId,
            extractedText,
            additives,
            status: 'completed'
          }
        });

      } catch (processingError) {
        console.error(`Processing error for job ${jobId}:`, processingError);
        
        // Processing failed

        res.status(500).json({
          success: false,
          error: 'Failed to process image. Please try again.'
        });
      }

    } catch (error) {
      console.error('Image processing endpoint error:', error);
      res.status(500).json({
        success: false,
        error: 'Internal server error'
      });
    }
  }
};


/**
 * Processes an image buffer with OCR using Google Cloud Vision API.
 * Provides high-accuracy text detection optimized for Korean and English.
 * 
 * @param {Buffer} imageBuffer - The image buffer to process
 * @returns {Promise<string>} The extracted text from the image
 * 
 * @private
 */
async function processImageWithVisionAPI(imageBuffer: Buffer): Promise<string> {
  try {
    console.log('NODE_ENV:', process.env.NODE_ENV);
    console.log('GOOGLE_APPLICATION_CREDENTIALS:', process.env.GOOGLE_APPLICATION_CREDENTIALS);
    console.log('Starting Google Cloud Vision OCR processing...');
    
    // Get project ID to verify authentication
    try {
      const projectId = await visionClient.getProjectId();
      console.log('‚úÖ Authenticated with project:', projectId);
    } catch (authError: any) {
      console.error('‚ùå Authentication failed:', authError.message);
      throw new Error(`Vision API authentication failed: ${authError.message}`);
    }
    
    // Call Google Cloud Vision API for text detection
    const [result] = await visionClient.textDetection({
      image: {
        content: imageBuffer.toString('base64'),
      },
    });

    console.log('‚úÖ Vision API call completed successfully');

    // Extract text from the response
    const extractedText = result.fullTextAnnotation?.text || '';
    
    // Clean up the extracted text
    const cleanedText = extractedText
      .replace(/\n+/g, ' ')  // Replace newlines with spaces
      .replace(/\s+/g, ' ')  // Replace multiple spaces with single space
      .replace(/[^\w\sÍ∞Ä-Ìû£„Ñ±-„Öé„Öè-„Ö£,;:()\-]/g, ' ')  // Keep only alphanumeric, Korean, and basic punctuation
      .trim();               // Remove leading/trailing whitespace

    console.log('Google Cloud Vision OCR completed successfully');
    console.log('Raw OCR result:', extractedText);
    console.log('Cleaned OCR result:', cleanedText);

    // Return fallback text if OCR result is too short or empty
    if (cleanedText.length < 3) {
      console.warn('OCR result too short, using fallback text');
      return getFallbackIngredients();
    }

    // Additional validation - check if result contains mostly meaningful content
    if (isValidIngredientText(cleanedText)) {
      return cleanedText;
    } else {
      console.warn('OCR result seems invalid, using fallback text');
      return getFallbackIngredients();
    }
  } catch (error: any) {
    console.error('‚ùå Google Cloud Vision OCR processing failed:', error);
    
    // Log detailed error information for debugging
    if (error.code) {
      console.error('Error code:', error.code);
    }
    if (error.status) {
      console.error('HTTP status:', error.status);
    }
    if (error.details) {
      console.error('Error details:', error.details);
    }
    
    // Check for common error types
    if (error.message?.includes('PERMISSION_DENIED')) {
      console.error('üîí Permission denied - check service account permissions');
    } else if (error.message?.includes('QUOTA_EXCEEDED')) {
      console.error('üìä Quota exceeded - check API limits');
    } else if (error.message?.includes('API_KEY_INVALID')) {
      console.error('üîë Invalid API key - check credentials');
    } else if (error.code === 'ENOTFOUND' || error.code === 'ECONNRESET') {
      console.error('üåê Network error - check internet connection');
    }
    
    // Return fallback text on OCR failure
    console.warn('‚ö†Ô∏è OCR failed, using fallback text');
    return getFallbackIngredients();
  }
}

/**
 * Validates if the extracted text appears to contain food ingredients.
 * 
 * @param {string} text - The text to validate
 * @returns {boolean} True if text appears to contain ingredients
 * 
 * @private
 */
function isValidIngredientText(text: string): boolean {
  // Common food-related keywords in Korean and English
  const foodKeywords = [
    'Ï≤®Í∞ÄÎ¨º', 'ÏÑ±Î∂Ñ', 'ÏõêÎ£å', 'Ïû¨Î£å', 'ÏÇ∞', 'Ïóº', 'Îãπ', 'Î£å',
    'acid', 'sodium', 'sugar', 'extract', 'oil', 'powder',
    'ÎÇòÌä∏Î•®', 'ÏπºÏäò', 'ÏπºÎ•®', 'Ïù∏ÏÇ∞', 'Íµ¨Ïó∞ÏÇ∞', 'ÏïÑÏä§ÏΩîÎ•¥ÎπàÏÇ∞'
  ];
  
  const lowerText = text.toLowerCase();
  return foodKeywords.some(keyword => lowerText.includes(keyword.toLowerCase())) || 
         text.length > 10; // Assume longer texts are more likely to be valid
}

/**
 * Returns a fallback ingredient list for testing and demo purposes.
 * 
 * @returns {string} Fallback ingredient text
 * 
 * @private
 */
function getFallbackIngredients(): string {
  const fallbacks = [
    "ÏïàÏãùÌñ•ÏÇ∞ÎÇòÌä∏Î•®, Í∏ÄÎ£®ÌÉêÏÇ∞ÎÇòÌä∏Î•®, Íµ¨Ïó∞ÏÇ∞, ÏïÑÏä§ÌååÌÉê, Ïπ¥ÎùºÍ∏∞ÎÇú",
    "Ï†ÅÏÉâ 40Ìò∏, Ìô©ÏÉâ 5Ìò∏, ÏàòÌÅ¨ÎûÑÎ°úÏä§, Î†àÏãúÌã¥, Í≥ºÎãπÌè¨ÎèÑÎãπÏï°",
    "BHA, ÏïÑÏßàÏÇ∞ÎÇòÌä∏Î•®, ÏÜåÎ•¥ÎπàÏÇ∞, ÌÜ†ÏΩîÌéòÎ°§, Ïù∏ÏÇ∞"
  ];
  
  // Return a random fallback for demo variety
  return fallbacks[Math.floor(Math.random() * fallbacks.length)];
}